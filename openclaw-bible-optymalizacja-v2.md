# OpenClaw Bible ‚Äî Optymalizacja Fleetu Agent√≥w v2.0

## Stan na: 7 lutego 2026

---

## 1. Architektura Promptu ‚Äî Maksymalizacja Cache Hit Rate

### 1.1 Problem

Ka≈ºdy agent ≈Çaduje przy starcie sesji: SOUL.md + PROTOCOL.md + USER.md + security rules + TASK_STATE.md + HANDOFF.md. Przy czterech agentach (Orchestrator, Developer, Researcher, Admin) to czterokrotne przetwarzanie w du≈ºej mierze identycznego contentu. Ollama od wersji 0.5+ wspiera natywny prompt caching ‚Äî cachedowane prefiksy przyspieszajƒÖ first-token latency o 40-60%, ale tylko je≈õli statyczny content jest **zawsze na poczƒÖtku** system promptu.

### 1.2 Zasada: Static First, Dynamic Last

Struktura system promptu **ka≈ºdego agenta** musi wyglƒÖdaƒá tak:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  WARSTWA 1: SOUL.md (identyczna per agent)  ‚îÇ  ‚Üê CACHE HIT (stabilna)
‚îÇ  Core principles, values, security rules    ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  WARSTWA 2: PROTOCOL.md (identyczna)        ‚îÇ  ‚Üê CACHE HIT (stabilna)
‚îÇ  Memory rules, handoff, rotacja, rate limits‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  WARSTWA 3: ROLE.md (per agent, stabilna)   ‚îÇ  ‚Üê CACHE HIT (zmienia siƒô rzadko)
‚îÇ  Rola agenta, dozwolone narzƒôdzia, sandbox  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  WARSTWA 4: USER.md (stabilna)              ‚îÇ  ‚Üê CACHE HIT (zmienia siƒô rzadko)
‚îÇ  Kontekst u≈ºytkownika, cele, metryki        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  WARSTWA 5: TASK_STATE.md (dynamiczna)      ‚îÇ  ‚Üê BEZ CACHE (zmienia siƒô co sesjƒô)
‚îÇ  Aktualny stan zadania, faza, plan          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  WARSTWA 6: HANDOFF.md (dynamiczna)         ‚îÇ  ‚Üê BEZ CACHE (zmienia siƒô co sesjƒô)
‚îÇ  Kontekst z poprzedniej sesji               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  WARSTWA 7: memory/YYYY-MM-DD.md            ‚îÇ  ‚Üê BEZ CACHE (daily notes)
‚îÇ  Notatki z dnia, je≈õli istniejƒÖ             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 1.3 Dodaj do SOUL.md ka≈ºdego agenta

```markdown
## PROMPT STRUCTURE RULE

System prompt MUSI byƒá zorganizowany w nastƒôpujƒÖcej kolejno≈õci:
1. SOUL.md (warto≈õci, zasady ‚Äî NIGDY nie modyfikuj w trakcie sesji)
2. PROTOCOL.md (procedury ‚Äî NIGDY nie modyfikuj w trakcie sesji)
3. ROLE.md (definicja roli ‚Äî modyfikuj tylko przy restrukturyzacji)
4. USER.md (kontekst u≈ºytkownika ‚Äî modyfikuj rzadko)
5. TASK_STATE.md (stan zadania ‚Äî dynamiczny, aktualizuj czƒôsto)
6. HANDOFF.md (przekazanie ‚Äî dynamiczny, generowany automatycznie)
7. Daily notes (opcjonalne ‚Äî ≈Çaduj on-demand przez memory_search())

ZASADA: Warstwy 1-4 to "frozen prefix". Nie modyfikuj ich w trakcie sesji.
Warstwy 5-7 to "hot suffix". Aktualizuj je aktywnie.
Ta struktura maksymalizuje cache hit rate w Ollama/LLM inference.
```

### 1.4 Konfiguracja Ollama dla cache

```json5
// Dodaj do konfiguracji Ollama (lub parametr√≥w modelu)
{
  "num_ctx": 131072,        // Pe≈Çne okno kontekstowe GPT-120B
  "num_keep": -1,           // Zachowaj ca≈Çy system prompt w KV cache
  "cache_type": "q8_0",     // Skwantyzowany cache (oszczƒôdza VRAM)
  "num_predict": 4096       // Max tokens na odpowied≈∫
}
```

---

## 2. Event-Driven Health Check (zamiennik Heartbeat)

### 2.1 Problem z heartbeat

Domy≈õlny heartbeat OpenClaw odpytuje model co X minut ‚Äî nawet gdy agent jest idle. Przy czterech agentach na jednym GPU to ciƒÖg≈Çe obciƒÖ≈ºenie inference bez ≈ºadnej warto≈õci. Guide ScaleUP sugeruje przeniesienie heartbeatu na Ollama ‚Äî to krok w dobrƒÖ stronƒô, ale niewystarczajƒÖcy.

### 2.2 RozwiƒÖzanie: Event-Driven Status Reporting

Zamiast periodycznego heartbeatu, agent raportuje status **tylko gdy co≈õ siƒô zmienia**.

#### Triggery raportowania:

| Trigger | Kana≈Ç | Priorytet |
|---|---|---|
| Zmiana stanu (idle ‚Üí working ‚Üí blocked ‚Üí error) | Slack #alerts | NORMAL |
| Uko≈Ñczenie taska | Slack #{agent-channel} + Todoist update | NORMAL |
| B≈ÇƒÖd krytyczny | Slack #alerts + Telegram (do Ciebie) | HIGH |
| Przekroczenie progu kontekstu (70%+) | Slack #alerts | HIGH |
| Explicit ping od Orchestratora | Odpowied≈∫ na kanale ≈∫r√≥d≈Çowym | IMMEDIATE |
| Latency > 30s (degradacja) | Slack #alerts | HIGH |
| Brak aktywno≈õci > 4h (watchdog) | Slack #alerts | LOW |

#### Konfiguracja OpenClaw ‚Äî wy≈ÇƒÖczenie heartbeat + watchdog

```json5
// ~/.openclaw-{agent}/openclaw.json
{
  "heartbeat": {
    "every": "0",           // WY≈ÅƒÑCZONY ‚Äî zero idle inference
    "model": "none"
  },
  
  // Zastƒôpujemy watchdogiem na poziomie systemu (nie LLM)
  // Patrz sekcja 2.3
}
```

### 2.3 Systemowy Watchdog (bez inference)

Zamiast LLM-owego heartbeatu, u≈ºyj prostego skryptu bash/Python sprawdzajƒÖcego czy daemon ≈ºyje:

```bash
#!/bin/bash
# /opt/openclaw/watchdog.sh
# Uruchamiany przez systemd timer co 30 minut

AGENTS=("orchestrator:3001" "developer:3002" "researcher:3003" "admin:3004")

for agent_port in "${AGENTS[@]}"; do
    agent="${agent_port%%:*}"
    port="${agent_port##*:}"
    
    # Sprawd≈∫ czy daemon odpowiada (HTTP health endpoint, nie LLM inference)
    if ! curl -sf "http://localhost:${port}/health" > /dev/null 2>&1; then
        # Agent nie odpowiada ‚Äî wy≈õlij alert
        curl -X POST "https://api.telegram.org/bot${TG_TOKEN}/sendMessage" \
            -d "chat_id=${TG_CHAT_ID}" \
            -d "text=‚ö†Ô∏è Agent ${agent} (port ${port}) nie odpowiada!"
        
        # Opcjonalnie: restart daemona
        systemctl restart "openclaw-${agent}"
    fi
done
```

```ini
# /etc/systemd/system/openclaw-watchdog.timer
[Unit]
Description=OpenClaw Fleet Watchdog

[Timer]
OnCalendar=*:0/30
Persistent=true

[Install]
WantedBy=timers.target
```

### 2.4 Dodaj do PROTOCOL.md

```markdown
## STATUS REPORTING PROTOCOL

### Zasada: Event-driven, nie periodyczny

Agent NIE wysy≈Ça heartbeat√≥w. Agent raportuje status TYLKO gdy:

1. **State change**: idle ‚Üí working ‚Üí blocked ‚Üí error
   ‚Üí Wy≈õlij na Slack #{tw√≥j-kana≈Ç}: "[STATE] {nowy_stan}: {kr√≥tki opis}"

2. **Task complete**: uko≈Ñczenie zadania lub jednostki pracy
   ‚Üí Wy≈õlij na Slack #{tw√≥j-kana≈Ç}: "[DONE] {task_id}: {wynik}"
   ‚Üí Zaktualizuj Todoist

3. **Error**: b≈ÇƒÖd blokujƒÖcy lub nieoczekiwany
   ‚Üí Wy≈õlij na Slack #alerts: "[ERROR] {opis}"
   ‚Üí Je≈õli krytyczny ‚Üí eskaluj do Orchestratora

4. **Threshold warning**: kontekst > 70% LUB latency > 30s
   ‚Üí Wy≈õlij na Slack #alerts: "[THRESHOLD] context={X}% latency={Y}s"

5. **Ping response**: Orchestrator pyta o status
   ‚Üí Odpowiedz natychmiast z: stan, % kontekstu, bie≈ºƒÖce zadanie

ZABRONIONE: Periodyczne "I'm alive" messages. Zero idle inference.
```

---

## 3. Rate Limits Per Agent ‚Äî Guardrails Przeciw Runaway Automation

### 3.1 Problem

Autonomiczne agenty z cron jobami, webhookami i Lobster pipeline'ami mogƒÖ wpa≈õƒá w loop request√≥w. Jeden ≈∫le skonfigurowany pipeline (np. Researcher skanujƒÖcy BUR z b≈Çƒôdnym warunkiem stopu) mo≈ºe zablokowaƒá GPU na godziny.

### 3.2 Dodaj do PROTOCOL.md

```markdown
## RATE LIMITS

### Per Agent Limits

| Agent | Max requests/min | Max concurrent tools | Web search/batch | Cooldown |
|---|---|---|---|---|
| Orchestrator | 15 | 3 | 5 + 2min break | 5s between calls |
| Developer | 12 | 5 (exec heavy) | 3 + 2min break | 3s between calls |
| Researcher | 10 | 2 | 5 + 2min break | 10s between searches |
| Admin | 8 | 2 | 3 + 3min break | 5s between calls |

### Hard Stops

- Je≈õli HTTP 429 (rate limit) ‚Üí STOP, wait 5 minut, retry ONCE, je≈õli nadal 429 ‚Üí log + notify Orchestrator
- Je≈õli response timeout > 30s ‚Üí log jako threshold warning (patrz sekcja 4)
- Je≈õli 3 consecutive errors ‚Üí STOP, log, notify Orchestrator, wait for human
- Je≈õli GPU utilization > 95% przez > 5 min ‚Üí Admin i Researcher wstrzymujƒÖ requesty, priorytet dla Orchestratora i Developera

### Batch Rules

- ZAWSZE grupuj podobnƒÖ pracƒô w jeden request (np. "sprawd≈∫ 10 lead√≥w" = 1 request, NIE 10 request√≥w)
- Web search: max 5 queries per batch, potem 2-minutowy cooldown
- File operations: max 20 plik√≥w per batch
- Todoist: max 10 operacji per batch

### Priority Queue (przy GPU contention)

1. üî¥ Orchestrator ‚Äî zawsze pierwszy
2. üü† Developer ‚Äî drugi priorytet
3. üü° Researcher ‚Äî trzeci
4. üü¢ Admin ‚Äî najni≈ºszy, czeka je≈õli kolejka > 2

### Compute Budget (zastƒôpuje monetary budget)

Zamiast "$5/day" ‚Äî metryki compute:
- Max inference time per agent: 45 min/h (15 min idle minimum)
- Max total fleet inference: 150 min/h (10 min reserved headroom)
- Monitoring: Orchestrator odpytuje system-monitor co task completion
```

---

## 4. Latency jako Trigger Rotacji

### 4.1 Problem

Dotychczasowe progi rotacji opierajƒÖ siƒô wy≈ÇƒÖcznie na % wykorzystania kontekstu (35% warning, 50% rotate, 75% emergency). Dane z analizy log√≥w pokazujƒÖ, ≈ºe degradacja latency nie jest liniowa ‚Äî ro≈õnie wyk≈Çadniczo po pewnym punkcie (z 2-12s do 119s). Mo≈ºe siƒô zdarzyƒá, ≈ºe agent jest na 45% kontekstu, ale latency ju≈º wskazuje na degradacjƒô (np. przez z≈Ço≈ºony reasoning chain).

### 4.2 Zaktualizowane progi ‚Äî Dual Trigger System

```markdown
## ROTATION TRIGGERS (zaktualizowane)

Rotacja nastƒôpuje gdy KT√ìRYKOLWIEK z warunk√≥w jest spe≈Çniony:

### Trigger A: Context Usage (istniejƒÖcy)

| Pr√≥g | Akcja | Typ zadania |
|---|---|---|
| 35% | ‚ö° WARNING ‚Äî zapisz checkpoint | Coding |
| 40% | ‚ö° WARNING ‚Äî zapisz checkpoint | Debugging |
| 50% | ‚ö†Ô∏è ROTATE ‚Äî natychmiast zapisz pe≈Çny stan | Coding |
| 60% | ‚ö†Ô∏è ROTATE ‚Äî natychmiast zapisz pe≈Çny stan | Planning/Docs |
| 75% | üö® EMERGENCY ‚Äî jedna odpowied≈∫ i koniec | Wszystkie |

### Trigger B: Latency Degradation (NOWY)

| Warunek | Akcja |
|---|---|
| Response time > 20s (baseline < 10s) | ‚ö° WARNING ‚Äî zaloguj, monitoruj trend |
| Response time > 30s przez 2 kolejne odpowiedzi | ‚ö†Ô∏è ROTATE ‚Äî inicjuj handoff |
| Response time > 60s | üö® EMERGENCY ‚Äî natychmiast zapisz i zamknij |
| Response time > 30s AND context > 40% | ‚ö†Ô∏è ROTATE ‚Äî podw√≥jny sygna≈Ç, natychmiast |

### Trigger C: Quality Degradation (NOWY ‚Äî heurystyczny)

| Warunek | Akcja |
|---|---|
| Agent powtarza tƒô samƒÖ akcjƒô 3x bez postƒôpu | ‚ö†Ô∏è ROTATE ‚Äî prawdopodobna halucynacja loopowa |
| Agent produkuje output niezgodny z TASK_STATE | ‚ö° WARNING ‚Äî zweryfikuj stan |
| Agent "zapomina" wcze≈õniejsze decyzje z tej sesji | üö® EMERGENCY ‚Äî kontekst zdegradowany |
```

### 4.3 Implementacja w Session Manager (Python)

Dodaj do istniejƒÖcego `SessionManager`:

```python
# Nowe pola w SessionConfig
@dataclass
class SessionConfig:
    # ... istniejƒÖce pola ...
    
    # Latency triggers (NOWE)
    latency_warning_threshold: float = 20.0      # sekundy
    latency_rotate_threshold: float = 30.0        # sekundy
    latency_emergency_threshold: float = 60.0     # sekundy
    latency_rotate_consecutive: int = 2           # ile kolejnych > threshold
    latency_baseline: float = 10.0                # oczekiwany normalny czas
    
    # Quality triggers (NOWE)
    max_repeated_actions: int = 3                 # loop detection
    
# Nowe pola w SessionState
@dataclass
class SessionState:
    # ... istniejƒÖce pola ...
    
    # Latency tracking (NOWE)
    response_times: list = field(default_factory=list)
    consecutive_slow_responses: int = 0
    
    @property
    def avg_latency(self) -> float:
        if not self.response_times:
            return 0.0
        return sum(self.response_times[-10:]) / len(self.response_times[-10:])
    
    @property
    def last_latency(self) -> float:
        return self.response_times[-1] if self.response_times else 0.0


# Nowa metoda w SessionManager
def check_latency_threshold(self, response_time: float) -> Optional[str]:
    """Sprawd≈∫ czy latency wskazuje na degradacjƒô."""
    self.state.response_times.append(response_time)
    
    # Emergency: pojedyncza odpowied≈∫ > 60s
    if response_time > self.config.latency_emergency_threshold:
        self.logger.warning(f"üö® LATENCY EMERGENCY: {response_time:.1f}s")
        return "emergency"
    
    # Rotate: consecutive slow responses
    if response_time > self.config.latency_rotate_threshold:
        self.state.consecutive_slow_responses += 1
        if self.state.consecutive_slow_responses >= self.config.latency_rotate_consecutive:
            self.logger.warning(
                f"‚ö†Ô∏è LATENCY ROTATE: {self.state.consecutive_slow_responses}x "
                f">{self.config.latency_rotate_threshold}s"
            )
            return "rotate"
    else:
        self.state.consecutive_slow_responses = 0  # reset counter
    
    # Dual trigger: latency + context
    usage = self.get_usage_ratio()
    if response_time > self.config.latency_rotate_threshold and usage > 0.4:
        self.logger.warning(
            f"‚ö†Ô∏è DUAL TRIGGER: latency={response_time:.1f}s + context={usage:.0%}"
        )
        return "rotate"
    
    # Warning
    if response_time > self.config.latency_warning_threshold:
        self.logger.info(f"‚ö° LATENCY WARNING: {response_time:.1f}s")
        return "warning"
    
    return None
```

### 4.4 Integracja z g≈Ç√≥wnƒÖ pƒôtlƒÖ

```python
# W metodzie run_session(), po wywo≈Çaniu API:

import time

# --- 2. Wywo≈Çaj API z pomiarem czasu ---
start_time = time.monotonic()
response = self._call_api()
elapsed = time.monotonic() - start_time

if response is None:
    return "error"

# --- 2b. Sprawd≈∫ latency threshold (NOWE) ---
latency_threshold = self.check_latency_threshold(elapsed)

if latency_threshold == "emergency":
    # Nadpisuje inne thresholdy ‚Äî natychmiastowy zapis i zamkniƒôcie
    return self._rotate_session("latency_emergency")

if latency_threshold == "rotate" and not self.state.rotation_triggered:
    self.messages.append(self.inject_signal("rotate"))
    self.state.rotation_triggered = True

# --- 3. Przetw√≥rz odpowied≈∫ (istniejƒÖcy kod) ---
self._process_response(response)
```

---

## 5. Session Initialization ‚Äî Lean Context Loading

### 5.1 Zasada (zintegrowana z istniejƒÖcym Boot Sequence)

Tw√≥j Mandatory Boot Sequence jest ju≈º lepszy ni≈º propozycja ScaleUP, ale warto dodaƒá explicit "DO NOT LOAD" list, ≈ºeby agent nie ≈Çadowa≈Ç niepotrzebnego kontekstu:

### 5.2 Dodaj do PROTOCOL.md (sekcja Boot Sequence)

```markdown
## BOOT SEQUENCE (zaktualizowany)

### Na poczƒÖtku KA≈ªDEJ sesji, ZANIM zrobisz cokolwiek:

KROK 1 ‚Äî ZA≈ÅADUJ (w tej kolejno≈õci):
  1. SOUL.md (je≈õli nie jest w system prompt ‚Äî powinien byƒá)
  2. PROTOCOL.md (je≈õli nie jest w system prompt ‚Äî powinien byƒá)
  3. ROLE.md (twoja rola ‚Äî powinien byƒá w system prompt)
  4. TASK_STATE.md (cat .agent/TASK_STATE.md)
  5. HANDOFF.md (cat .agent/HANDOFF.md ‚Äî je≈õli istnieje)
  6. memory/YYYY-MM-DD.md (je≈õli istnieje ‚Äî dzisiejsze notatki)

KROK 2 ‚Äî NIE ≈ÅADUJ automatycznie:
  ‚ùå MEMORY.md (pe≈Çna historia ‚Äî ≈Çaduj on-demand przez memory_search())
  ‚ùå Poprzednie session logi (SESSION_LOG.jsonl ‚Äî tylko do analizy)
  ‚ùå Pliki kodu/projekt√≥w (≈Çaduj dopiero gdy potrzebne do bie≈ºƒÖcego taska)
  ‚ùå Historiƒô konwersacji z poprzednich sesji
  ‚ùå Dokumentacjƒô narzƒôdzi (≈Çaduj on-demand)

KROK 3 ‚Äî POTWIERD≈π rozumienie:
  "Rozumiem stan:
   Mission: {z TASK_STATE}
   Phase: {z TASK_STATE}
   Last action: {z TASK_STATE}
   Next step: {z HANDOFF lub TASK_STATE}
   Kontynuujƒô."

KROK 4 ‚Äî DOPIERO TERAZ przystƒÖp do pracy.

### On-Demand Loading Rule

Gdy potrzebujesz informacji z przesz≈Ço≈õci:
  ‚Üí U≈ºyj memory_search("{keyword}") ‚Äî zwraca TYLKO relevantny snippet
  ‚Üí U≈ºyj memory_get("{specific_id}") ‚Äî pobiera konkretny wpis
  ‚Üí NIE ≈Çaduj ca≈Çego pliku MEMORY.md
  ‚Üí NIE ≈Çaduj wszystkich daily notes naraz

Ta zasada utrzymuje kontekst startowy na ~8-12KB zamiast 50KB+.
```

---

## 6. Model Tiering dla Lokalnego GPU

### 6.1 Problem

Czterech agent√≥w na jednym RTX 3090 (24GB VRAM) z GPT-120B to potencjalny bottleneck. Nie wszyscy agenci potrzebujƒÖ pe≈Çnej mocy modelu.

### 6.2 Strategia: Dwa Profile Modelu

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  PROFIL A: GPT-120B Full (FP16 lub Q8)              ‚îÇ
‚îÇ  ‚Üí Orchestrator (reasoning, delegacja, strategia)   ‚îÇ
‚îÇ  ‚Üí Developer (coding, architecture, debugging)      ‚îÇ
‚îÇ  Parametry: num_ctx=131072, temperature=0.3          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  PROFIL B: GPT-120B Quantized (Q4_K_M / AWQ 4-bit) ‚îÇ
‚îÇ  ‚Üí Researcher (search, analysis ‚Äî mniej krytyczny)  ‚îÇ
‚îÇ  ‚Üí Admin (rutynowe taski, kalendarz, maile)         ‚îÇ
‚îÇ  ‚Üí Watchdog responses                               ‚îÇ
‚îÇ  Parametry: num_ctx=65536, temperature=0.5           ‚îÇ
‚îÇ  VRAM: ~40-50% mniej ni≈º Profil A                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### 6.3 Konfiguracja Ollama ‚Äî dwa modele

```bash
# Profil A: pe≈Çny model
ollama create gpt120b-full -f Modelfile.full

# Profil B: skwantyzowany
ollama create gpt120b-lite -f Modelfile.lite
```

```
# Modelfile.full
FROM gpt-120b
PARAMETER num_ctx 131072
PARAMETER temperature 0.3
PARAMETER num_keep -1

# Modelfile.lite  
FROM gpt-120b-q4km
PARAMETER num_ctx 65536
PARAMETER temperature 0.5
PARAMETER num_keep -1
```

### 6.4 Mapowanie w OpenClaw config per agent

```json5
// ~/.openclaw-orchestrator/openclaw.json
{
  "model": "ollama/gpt120b-full"
}

// ~/.openclaw-developer/openclaw.json
{
  "model": "ollama/gpt120b-full"
}

// ~/.openclaw-researcher/openclaw.json
{
  "model": "ollama/gpt120b-lite"
}

// ~/.openclaw-admin/openclaw.json
{
  "model": "ollama/gpt120b-lite"
}
```

### 6.5 Fallback: Orchestrator na Claude Opus (opcjonalnie)

Je≈õli jako≈õƒá reasoning Orchestratora na lokalnym modelu jest niewystarczajƒÖca dla z≈Ço≈ºonych decyzji architekturalnych:

```json5
// ~/.openclaw-orchestrator/openclaw.json
{
  "model": "anthropic/claude-opus-4-5",        // Primary: cloud API
  "models": {
    "ollama/gpt120b-full": { "alias": "local" } // Fallback: lokalny
  }
}
```

Koszt: ~$15/1M token√≥w dla Opus, ale Orchestrator wysy≈Ça relatywnie ma≈Ço request√≥w (deleguje, nie wykonuje). Szacowany koszt: $5-15/miesiƒÖc.

---

## 7. Compute Monitoring ‚Äî Metryki GPU zamiast Dolar√≥w

### 7.1 Metryki do ≈õledzenia

| Metryka | Narzƒôdzie | Alert threshold |
|---|---|---|
| GPU Utilization % | `nvidia-smi` / system-monitor | > 95% przez > 5 min |
| VRAM Usage | `nvidia-smi` | > 22GB / 24GB |
| Inference tokens/sec | Ollama logs | < 5 tok/s (degradacja) |
| Queue wait time | Ollama metrics | > 10s (contention) |
| First-token latency | Session Manager | > 5s (cache miss / overload) |
| Response time (E2E) | Session Manager | > 30s (patrz sekcja 4) |

### 7.2 Monitoring Script (cron co 5 minut)

```bash
#!/bin/bash
# /opt/openclaw/gpu-monitor.sh

GPU_UTIL=$(nvidia-smi --query-gpu=utilization.gpu --format=csv,noheader,nounits)
VRAM_USED=$(nvidia-smi --query-gpu=memory.used --format=csv,noheader,nounits)
VRAM_TOTAL=$(nvidia-smi --query-gpu=memory.total --format=csv,noheader,nounits)
VRAM_PCT=$((VRAM_USED * 100 / VRAM_TOTAL))
TEMP=$(nvidia-smi --query-gpu=temperature.gpu --format=csv,noheader,nounits)

# Log
echo "$(date -Iseconds) GPU:${GPU_UTIL}% VRAM:${VRAM_USED}/${VRAM_TOTAL}MB (${VRAM_PCT}%) TEMP:${TEMP}¬∞C" \
    >> /var/log/openclaw/gpu-metrics.log

# Alerty
if [ "$GPU_UTIL" -gt 95 ]; then
    # Sprawd≈∫ czy trwa to > 5 minut (por√≥wnaj z poprzednim logiem)
    PREV_HIGH=$(tail -5 /var/log/openclaw/gpu-metrics.log | grep -c "GPU:9[5-9]\|GPU:100")
    if [ "$PREV_HIGH" -ge 5 ]; then
        curl -s -X POST "https://api.telegram.org/bot${TG_TOKEN}/sendMessage" \
            -d "chat_id=${TG_CHAT_ID}" \
            -d "text=üî¥ GPU overload: ${GPU_UTIL}% przez >5min. VRAM: ${VRAM_PCT}%. Temp: ${TEMP}¬∞C"
    fi
fi

if [ "$VRAM_PCT" -gt 92 ]; then
    curl -s -X POST "https://api.telegram.org/bot${TG_TOKEN}/sendMessage" \
        -d "chat_id=${TG_CHAT_ID}" \
        -d "text=‚ö†Ô∏è VRAM critical: ${VRAM_USED}/${VRAM_TOTAL}MB (${VRAM_PCT}%)"
fi

if [ "$TEMP" -gt 85 ]; then
    curl -s -X POST "https://api.telegram.org/bot${TG_TOKEN}/sendMessage" \
        -d "chat_id=${TG_CHAT_ID}" \
        -d "text=üå°Ô∏è GPU temp: ${TEMP}¬∞C ‚Äî rozwa≈º throttling"
fi
```

### 7.3 Priority Queue przy contention

Gdy GPU jest przeciƒÖ≈ºone, Orchestrator wymusza priorytety:

```markdown
## GPU CONTENTION PROTOCOL

Gdy GPU utilization > 90% przez > 2 minuty:

1. Admin ‚Üí PAUSE (wstrzymaj wszystkie requesty, czekaj na sygna≈Ç)
2. Researcher ‚Üí PAUSE (chyba ≈ºe ma task CRITICAL)
3. Developer ‚Üí kontynuuje normalnie
4. Orchestrator ‚Üí kontynuuje normalnie

Wznowienie: gdy GPU < 80% przez > 1 minutƒô
Orchestrator wysy≈Ça na Slack: "[RESUME] GPU contention resolved"

Agent w PAUSE:
- NIE wysy≈Ça request√≥w do Ollama
- Zapisuje stan do TASK_STATE.md
- Czeka na "[RESUME]" na Slack #alerts
- Je≈õli PAUSE > 30 minut ‚Üí zapisz pe≈Çny stan, zamknij sesjƒô gracefully
```

---

## 8. Pe≈Çna Checklist Wdro≈ºenia

### Faza 1: Restrukturyzacja Prompt√≥w (Dzie≈Ñ 1)

- [ ] Przeorganizuj system prompt ka≈ºdego agenta wg kolejno≈õci z sekcji 1.2
- [ ] Wyodrƒôbnij ROLE.md per agent (oddziel od SOUL.md)
- [ ] Dodaj PROMPT STRUCTURE RULE do SOUL.md
- [ ] Dodaj SESSION INITIALIZATION update do PROTOCOL.md (sekcja 5.2)
- [ ] Skonfiguruj Ollama cache parameters (sekcja 1.4)
- [ ] Zweryfikuj: `session_status` powinien pokazaƒá context ~8-12KB na starcie

### Faza 2: Event-Driven Health (Dzie≈Ñ 2)

- [ ] Wy≈ÇƒÖcz heartbeat we wszystkich agentach (`"every": "0"`)
- [ ] Dodaj STATUS REPORTING PROTOCOL do PROTOCOL.md (sekcja 2.4)
- [ ] Wdr√≥≈º watchdog.sh jako systemd timer (sekcja 2.3)
- [ ] Wdr√≥≈º gpu-monitor.sh jako cron co 5 minut (sekcja 7.2)
- [ ] Przetestuj: wy≈ÇƒÖcz jednego agenta, sprawd≈∫ czy alert przychodzi na Telegram

### Faza 3: Rate Limits i Guardrails (Dzie≈Ñ 3)

- [ ] Dodaj RATE LIMITS do PROTOCOL.md (sekcja 3.2)
- [ ] Dodaj GPU CONTENTION PROTOCOL do PROTOCOL.md (sekcja 7.3)
- [ ] Przetestuj: ustaw niskie limity, uruchom pipeline, zweryfikuj ≈ºe agent siƒô zatrzymuje

### Faza 4: Latency Monitoring (Dzie≈Ñ 4)

- [ ] Dodaj latency tracking do Session Manager (sekcja 4.3 i 4.4)
- [ ] Zaktualizuj progi rotacji w PROTOCOL.md (sekcja 4.2)
- [ ] Dodaj latency do log√≥w sesji (SESSION_LOG.jsonl)
- [ ] Przetestuj: sztucznie op√≥≈∫nij response, zweryfikuj rotacjƒô

### Faza 5: Model Tiering (Dzie≈Ñ 5-7)

- [ ] Stw√≥rz dwa profile Ollama: gpt120b-full i gpt120b-lite (sekcja 6.3)
- [ ] Zmapuj profile do agent√≥w (sekcja 6.4)
- [ ] Przetestuj jako≈õƒá Researcher i Admin na gpt120b-lite
- [ ] Opcjonalnie: przetestuj Orchestrator na Claude Opus vs lokalny
- [ ] Zmierz: VRAM usage z dwoma profilami vs jednym

---

## 9. Por√≥wnanie: Przed i Po Optymalizacji

| Metryka | PRZED | PO |
|---|---|---|
| Context na starcie sesji | 50KB+ | 8-12KB |
| Idle GPU inference (heartbeat) | CiƒÖg≈Çe, 4 agenty | Zero (event-driven) |
| Trigger rotacji | Tylko % kontekstu | % kontekstu + latency + quality |
| Rate limiting | Brak | Per agent, z priorytetami |
| GPU monitoring | Brak / manualny | Automatyczny z alertami Telegram |
| Model per agent | Jeden dla wszystkich | Tiered: full (Orch+Dev) / lite (Res+Admin) |
| Prompt cache hit rate | Losowy (brak struktury) | ~80-90% (frozen prefix) |
| Concurrent agent capacity | 1-2 (GPU bottleneck) | 3-4 (z tieringiem + queue) |
| ≈öredni first-token latency | 3-8s | 1-4s (z cache) |
| Recovery po crash | Manual / losowy | Automatyczny Boot Sequence + TASK_STATE |

---

## 10. ≈πr√≥d≈Ça i Referencje

- **ScaleUP Media ‚Äî OpenClaw Token Optimization Guide** (Matt Ganzak, luty 2026): Session init, model routing, prompt caching
- **Nasza architektura Bible**: Layered Memory System, Handoff Protocol, Session Manager, Boot Sequence
- **Analiza log√≥w OpenClaw** (≈∫r√≥d≈Ço community): Degradacja latency 2-12s ‚Üí 119s przy rozbudowanym kontek≈õcie
- **Ollama docs**: Prompt caching od v0.5+, KV cache configuration, multi-model serving
- **OpenClaw FAQ**: Multi-agent routing "token heavy" ‚Äî potwierdzenie s≈Çuszno≈õci architektury niezale≈ºnych instancji

---

*Dokument wygenerowany 7 lutego 2026. Wersja 2.0 ‚Äî integracja istniejƒÖcej architektury Bible z optymalizacjami ScaleUP + autorskie rozszerzenia.*
